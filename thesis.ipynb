{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doctoral Thesis\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## code snippet\n",
    "1. <b style=\"color:red\">XXX</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hongwei Wang - Network Representation Learning Based Recommender System\n",
    "\n",
    "### Abstract\n",
    "1. 对用户画像、物品属性和<b style=\"color:red\">上下文</b>等信息进行建模，推断出用户的兴趣爱好，并向用户推荐感兴趣的物品。\n",
    "    1. 主信息：用户和产品的交互历史\n",
    "    1. 辅助信息(side information)：\n",
    "        1. 用户画像user profile（如年龄、性别等）\n",
    "        1. 物品属性item attributes（如物品类别、描述、价格等）\n",
    "        1. 上下文信息contexts（如当前会话信息、用户位置等）\n",
    "1. 实用的推荐算法需要有很强的扩展性，可以方便地融合各种辅助信息\n",
    "1. 一类辅助信息:拥有网络结构的信息\n",
    "    1. 用户之间的在线社交网络(social network)\n",
    "        1. (基于特征): SHINE\n",
    "        1. (基于结构): JTS-MF\n",
    "    1. 物品之间的知识图谱(knowledge graph): \n",
    "        1. (基于特征): DKN(依次学习法) + MKR(交替学习法)\n",
    "        1. (基于结构:宽度优先搜索): RippleNet(向外传播法) + KGCN(向内聚合法)\n",
    "    1. 用户和物品的交互本身就构成了一个交互图(interaction graph) --> GraphGAN\n",
    "1. 同质性假设：两个在社交网络中关系紧密的用户的偏好也很可能会相似\n",
    "\n",
    "### Ch1 Introduction\n",
    "1. background:\n",
    "    1. dilemma: information overload\n",
    "    1. 推荐问题从本质上说就是代替用户评估其从未看过、接触过和使用过的物品\n",
    "    1. 基于特征的推荐:以特征向量作为输入的通用推荐算法\n",
    "        1. 特征：在通用的机器学习框架下，辅助信息可以被统一表示为特征向量\n",
    "    1. 一类特殊的特征：拥有网络结构的特征\n",
    "1. 推荐系统概述：\n",
    "    1. 传统分类：\n",
    "        1. 基于内容: 针对物品/用户的描述来定义物品/用户的属性，定义物品/用户之间的相似度，根据历史信息计算相似度，进行推荐\n",
    "            1. 优点：\n",
    "                1. 对用户兴趣可以很好的建模\n",
    "                1. 增加物品属性维度，可以获得更好的推荐精度\n",
    "            1. 缺点：\n",
    "                1. 物品的属性有限，自动提取仍比较困难（<b style=\"color:gold\">深度学习技术可以提取有效特征</b>）\n",
    "                1. 只能推荐和用户历史高度匹配的物品，无法帮助用户发现新的兴趣和爱好\n",
    "        1. 协同滤波（RecSys的核心）：根据其他相似用户对于某物品的评分来预测某用户对于该物品的评分\n",
    "            1. 目标：从机器学习的角度可以看成<b style=\"color:gold\">拟合用户和物品之间的交互函数</b>\n",
    "            1. 假设条件：\n",
    "                1. 在过去拥有相似偏好的用户在未来也有相似的偏好\n",
    "                1. 用户对偏好随时间变化相对稳定\n",
    "            1. 分类：\n",
    "                1. 基于记忆(memroy-based): 其它用户对某物品的评分来预测某用户对该物品的评分。 \n",
    "                   $r_{c, s}=\\underset{c^{\\prime} \\in C}{\\operatorname{agg}} r_{c^{\\prime}, s}$\n",
    "                1. 基于模型(model-based)：通过机器学习方法，使用评分集子学习出一个全局模型，然后基于模型来预测缺失的评分。\n",
    "            1. 特点：CF主要使用用户对物品的历史交互数据（反馈数据）建立推荐算法\n",
    "            1. 反馈数据分类：是否反映用户对物品的喜好程度\n",
    "                1. 显式反馈explicit feedback: 直接反应喜好，如：评分\n",
    "                    1. (早期)常见任务：评分预测：\n",
    "                        1. input: 三元组$<u, i, r_{ui}>$或二维交互矩阵\n",
    "                        1. output: $\\hat{r}_{ui}$\n",
    "                        1. 难点：data sparsity\n",
    "                    1. 基于显式反馈的评分预测系统只优化交互矩阵中的观察数据，\n",
    "                       完全忽略缺失数据 $\\longrightarrow$ 泛化差 $\\longrightarrow$ 缺失数据的建模\n",
    "                1. 隐式反馈implicit feedback: 侧面反应喜好，如：点击、购买、看视频、听音乐\n",
    "                    1. 特点：\n",
    "                        1. 选择偏差较小（相对显示反馈）\n",
    "                        1. 规模相对较大（相对显示反馈）\n",
    "                    1. 缺失数据的建模在基于隐式反馈的推荐方法中得到了广泛的研究和使用。\n",
    "            1. 总结：\n",
    "                1. 优点：可以很好地支持用户发现潜在的兴趣偏好 $\\longleftarrow$ 同质性假设\n",
    "                1. 缺点：\n",
    "                    1. cold start：对新加入的用户和物品都无法给出准确的推荐\n",
    "                    1. data sparsity：显式反馈的计算结果不稳定，受异常值影响较大 $\\longleftarrow$ 只考虑观察到的数据\n",
    "                    1. 没有辅助信息\n",
    "        1. 混合方法：\n",
    "            1. 分类：根据不同的混合方式\n",
    "                1. 混合结果：分别实现基于内容的方法和协同过滤，然后结合两者的预测结果\n",
    "                1. 在协同过滤中加入一些基于内容的特征。\n",
    "                1. 在基于内容的方法中加入一些协同过滤的特征。\n",
    "                1. 构造一个包含基于内容方法和协同过滤的统一模型。\n",
    "    1. 新的研究热点/方向：CF + side information\n",
    "        1. 上下文感知（context-aware）的推荐\n",
    "            1. 上下文的定义：<b style=\"color:gold\">环境</b>\n",
    "                1. 研究对象的附近个体的位置、身份等信息【39】\n",
    "                1. 任何可以被用来描述个体所处环境的特征的信息【40】\n",
    "        1. 跨域（cross-domain）推荐\n",
    "            1. 目标：利用源领域的知识（多数为用户偏好）辅助在目标领域中提高个性化推荐的准确度。\n",
    "            1. 分类：\n",
    "                1. 源领域和目标领域的用户完全重叠\n",
    "                1. 源领域和目标领域的用户部分重叠\n",
    "                1. 源领域和目标领域的用户完全不重叠\n",
    "        1. 基于深度学习（deep learning based）的推荐\n",
    "            1. 分类：\n",
    "                1. 基于数据的特征学习方法：提取辅助信息（语音，图像，文本）的有效表示添加到推荐系统中\n",
    "                    1. 【51】 音频特征(DNN)+音乐推荐\n",
    "                    1. 【52】 文本特征(Autoencoder)+文章推荐\n",
    "                    1. 【54】 图像特征(CNN)+社交网络的图片推荐\n",
    "                1. 作为通用的数据建模方法：拟合出较为复杂的预测函数，代替CF简单的线性映射关系。\n",
    "                    1. DeepFM【56】：在FM 中引入了一个深度模型来拟合特征之间复杂的交互关系\n",
    "                    1. Wide&Deep【57】\n",
    "                        1. Wide部分采用和分解机一样的线性回归模型\n",
    "                        1. Deep部分采用了基于特征表示学习的多层感知机模型\n",
    "                    1. DNN-based Youtube RecSys【58】\n",
    "                    1. NCF【59】\n",
    "                    1. DMF【61】\n",
    "1. 网络特征学习概述\n",
    "    1. background：\n",
    "        1. 图/网络数据结构\n",
    "            1. 广泛存在\n",
    "                1. 社交网络\n",
    "                1. 引用网络\n",
    "                1. 知识图谱\n",
    "            1. 应用繁多：\n",
    "                1. 连接预测\n",
    "                1. 节点分类\n",
    "                1. 推荐\n",
    "                1. 可视化\n",
    "        1. 网络特征学习（NRL/NE）：解决原始网络邻接矩阵中，每个节点的邻接向量冗长且稀疏的问题\n",
    "            1. 发展历程：\n",
    "                1. 2000年以前，NRL的主要表现形式是对高维数据进行降维\n",
    "                    1. 主成分分析PCA:\n",
    "                        1. 思路：尽可能保留数据的方差，保留低阶主成分，忽略高阶主成分\n",
    "                        1. 对于某些分类问题不是非常有效\n",
    "                    1. 线性判别分析LDA\n",
    "                        1. 思路（SVM类似）：将高维空间中的数据点映射到低维空间中，\n",
    "                           使得同类点之间的距离尽可能接近，不同类点之间的距离尽可能远\n",
    "                    1. 多维缩放MDS\n",
    "                        1. 思路：在低维空间中（近似）保持每一对点的距离等于它们在原始高维空间里的距离\n",
    "                1. 2000年左右：新的降维方法\n",
    "                    1. 流形学习（manifold learning）：假设高维数据分布在一个特定的低维空间结构（流形）\n",
    "                       上，然后试图在低维空间上保持原有高维空间中数据的结构特征\n",
    "                        1. 同态映射（isometric mapping，IsoMap）\n",
    "                            1. 只考虑高维空间中每个点和它最邻近的k个点的距离\n",
    "                            1. 基于这些（测地线）距离，计算所有点对的距离\n",
    "                            1. 调用多维缩放的算法进行降维，保持每个节点和其局部邻近节点之间的距离关系\n",
    "                        1. 局部线性嵌入（locally linear embedding）\n",
    "                            1. 在高维空间中计算每个点和它邻近节点的线性依赖关系\n",
    "                            1. 试图在低维空间中保持这种线性依赖关系\n",
    "                    1. 图拉普拉斯（graph Laplacian）/谱分析（spectral analysis）\n",
    "                        1. 拉普拉斯特征映射（Laplacian eigenmaps）\n",
    "                1. 2010年以后，高维数据仿真网络 $\\Longleftarrow$ 真实的网络结构\n",
    "                    1. 触发点：word2vec -- 利用SkipGram 模型来学习词的低维向量表示\n",
    "            1. 输入网络的种类\n",
    "                1. 同构图：网络中的节点和边的种类都只有一个\n",
    "                    1. 例子：引用网络\n",
    "                    1. 细化标准：无向/有向、无权重/有权重、无符号/有符号\n",
    "                1. 异构图：网络中的节点或边的种类不止一个\n",
    "                    1. 多媒体网络（multimedia network）\n",
    "                        1. 【80】\n",
    "                            1. 两种类别的节点：图像和文本\n",
    "                            1. 三种类别的边：图像-图像、图像-文本、文本-文本\n",
    "                        1. 【54】由用户和图像组成的网络\n",
    "                    1. 知识图谱（knowledge graph）：\n",
    "                        1. 节点代表实体，边代表关系\n",
    "                        1. 表达形式：三元组$(h, r, t)$，头实体h通过关系r连接到尾实体t\n",
    "                        1. 知识图谱表示学习（KGE）：\n",
    "                            1. $\\mathbf{h}+\\mathbf{r} \\approx \\mathbf{t}$\n",
    "                            1. 代表方法：TransE, TransR, TransH, TransD, ...\n",
    "                1. 带辅助信息的图：节点或边可能会携带标签信息、属性信息、特征信息等\n",
    "                1. 由非关系型数据转化成的图\n",
    "            1. 输出特征的种类\n",
    "                1. 输出节点的特征: 最常见\n",
    "                1. 输出边的特征：\n",
    "                    1. 常见于KGE中\n",
    "                    1. 应用：\n",
    "                        1. 关系抽取（relation extraction）\n",
    "                        1. 知识图谱补全（knowledge graph completion）\n",
    "                        1. 问答系统（question answering）\n",
    "                1. 输出混合特征: 不同的组成部分的特征组合\n",
    "                    1. 节点+边：子图\n",
    "                    1. 节点+团体（community）：团体\n",
    "                1. 输出全图的特征：\n",
    "                    1. 一个小型网络结构被表示成单个向量，似的图会得到相似的特征向量。\n",
    "                    1. 例子：蛋白质/分子结构\n",
    "            1. 典型方法\n",
    "                1. 矩阵分解（matrix factorization）：涵盖了几乎所有的传统方法\n",
    "                    1. PCA\n",
    "                    1. MDS\n",
    "                    1. IsoMap\n",
    "                    1. 谱分析：代表拉普拉斯特征映射（Laplacian eigenmaps）\n",
    "                1. 随机游走（random walk）\n",
    "                    1. 思路：受到word2vec启发，图 --> 由节点组成的“文档”\n",
    "                        1. 使用随机游走的方法，从图中采样出很多条路径\n",
    "                        1. 基于这些路径来学习节点的特征表示\n",
    "                    1. 代表：\n",
    "                        1. DeepWalk: RandomWalk + SkipGram\n",
    "                        1. Node2vec: 细粒度的DeepWalk\n",
    "                1. 深度学习（deep learning）\n",
    "                    1. 自编码器方法：SDNE\n",
    "                        1. 输入：每个节点用它的邻接向量表示\n",
    "                        1. 优化目标：对于每一条边，都让其两个点在自编码器的中间层输出尽量接近\n",
    "                    1. 卷积神经网络：HNE\n",
    "                1. 其它自定义损失函数（self-defined loss function）\n",
    "                    1. LINE：定义了一阶邻近关系和二阶邻近关系，设计了两个对应损失函数项\n",
    "                    1. KGE的各种方法\n",
    "1. 研究内容/文章安排\n",
    "   1. 研究目标：结合推荐系统和网络特征学习，利用网络特征学习的技术更好地融合网络结构的辅助信息，提高推荐的效率\n",
    "   1. 研究贡献：\n",
    "      1. u-i交互图建模\n",
    "         1. 生成模型generator：<b style=\"color:red\">？</b>\n",
    "            1. input: $v_i$\n",
    "            1. output: $p_{true}(v|v_i)$\n",
    "         1. 判别模型discriminator：<b style=\"color:red\">？</b>\n",
    "            1. input: $v_i,v_j$\n",
    "            1. output: $p(v_i,v_j)$\n",
    "      1. u-u端社交网络\n",
    "         1. 基于特征：<b style=\"color:red\">将结构信息用于特征向量学习</b>\n",
    "            1. 将社交网络中的用户（节点）映射到低维空间\n",
    "            1. 将得到的用户特征向量用于后续的推荐\n",
    "         1. 基于结构：<b style=\"color:red\">直接对结构信息进行建模</b>\n",
    "      1. i-i端KG融合：\n",
    "         1. 基于特征：将KG中的实体用KGE的方法表示成低维向量，试图解决KG的HIN性\n",
    "         1. 基于结构：采用宽度优先的思路，直观地建立知识传播模型\n",
    "            1. 外向传播：通过用户历史兴趣沿着知识图谱的边，向外传播，学到KG实体特征\n",
    "            1. 内向聚合："
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
